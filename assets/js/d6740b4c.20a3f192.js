"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[6545],{5830:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module-01-ros2/week-04/ch04-tf2-transforms","title":"Coordinate Transforms with TF2","description":"Learning Objectives","source":"@site/docs/module-01-ros2/week-04/ch04-tf2-transforms.md","sourceDirName":"module-01-ros2/week-04","slug":"/module-01-ros2/week-04/ch04-tf2-transforms","permalink":"/AI_COURSE_book/docs/module-01-ros2/week-04/ch04-tf2-transforms","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-01-ros2/week-04/ch04-tf2-transforms.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"ch04-tf2-transforms","title":"Coordinate Transforms with TF2","sidebar_label":"Coordinate Transforms","sidebar_position":5},"sidebar":"textbookSidebar","previous":{"title":"Python with rclpy","permalink":"/AI_COURSE_book/docs/module-01-ros2/week-04/ch03-python-rclpy"},"next":{"title":"Robot Modeling with URDF","permalink":"/AI_COURSE_book/docs/module-01-ros2/week-05/ch05-urdf-models"}}');var t=r(4848),i=r(8453);const o={id:"ch04-tf2-transforms",title:"Coordinate Transforms with TF2",sidebar_label:"Coordinate Transforms",sidebar_position:5},a="Coordinate Transforms with TF2",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"1. TF2 Library Fundamentals",id:"1-tf2-library-fundamentals",level:2},{value:"What is TF2?",id:"what-is-tf2",level:3},{value:"Core Concepts",id:"core-concepts",level:3},{value:"TF2 vs TF (Original)",id:"tf2-vs-tf-original",level:3},{value:"Key TF2 Packages",id:"key-tf2-packages",level:3},{value:"2. Coordinate Frames in Robotics",id:"2-coordinate-frames-in-robotics",level:2},{value:"Standard Frame Naming Conventions",id:"standard-frame-naming-conventions",level:3},{value:"Transform Tree Example",id:"transform-tree-example",level:3},{value:"Right-Handed Coordinate Systems",id:"right-handed-coordinate-systems",level:3},{value:"3. Broadcasting Transforms",id:"3-broadcasting-transforms",level:2},{value:"Static Transforms",id:"static-transforms",level:3},{value:"Dynamic Transforms",id:"dynamic-transforms",level:3},{value:"4. Listening to Transforms",id:"4-listening-to-transforms",level:2},{value:"Transform Lookup",id:"transform-lookup",level:3},{value:"Transforming Points",id:"transforming-points",level:3},{value:"Time Travel: Looking Up Past Transforms",id:"time-travel-looking-up-past-transforms",level:3},{value:"5. Command-Line Tools",id:"5-command-line-tools",level:2},{value:"View Transform Tree",id:"view-transform-tree",level:3},{value:"Echo Transforms in Real-Time",id:"echo-transforms-in-real-time",level:3},{value:"Monitor Transform Issues",id:"monitor-transform-issues",level:3},{value:"6. Debugging TF2 Issues",id:"6-debugging-tf2-issues",level:2},{value:"Common Problems",id:"common-problems",level:3},{value:"7. Practical Example: Object Detection in Map Frame",id:"7-practical-example-object-detection-in-map-frame",level:2},{value:"Summary",id:"summary",level:2},{value:"Review Questions",id:"review-questions",level:2},{value:"Hands-on Exercises",id:"hands-on-exercises",level:2},{value:"Exercise 1: Static Transform Publisher",id:"exercise-1-static-transform-publisher",level:3},{value:"Exercise 2: Dynamic Broadcaster",id:"exercise-2-dynamic-broadcaster",level:3},{value:"Exercise 3: Point Transformer",id:"exercise-3-point-transformer",level:3},{value:"Further Reading",id:"further-reading",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"coordinate-transforms-with-tf2",children:"Coordinate Transforms with TF2"})}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Understand the TF2 transform library and its role in robotics"}),"\n",(0,t.jsx)(n.li,{children:"Work with coordinate frames and the transform tree"}),"\n",(0,t.jsx)(n.li,{children:"Broadcast static and dynamic transforms"}),"\n",(0,t.jsx)(n.li,{children:"Look up transforms to convert between coordinate frames"}),"\n",(0,t.jsx)(n.li,{children:"Debug transform issues using ROS 2 tools"}),"\n",(0,t.jsx)(n.li,{children:"Apply TF2 in real robot applications"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsxs)(n.p,{children:["Every sensor and component on a robot has its own coordinate frame - the camera sees the world from one position, the LiDAR from another, wheels have their own reference points. ",(0,t.jsx)(n.strong,{children:"How do we relate measurements from all these different perspectives?"})]}),"\n",(0,t.jsxs)(n.p,{children:["This is the fundamental problem that ",(0,t.jsx)(n.strong,{children:"TF2"})," (Transform Library 2) solves. TF2 is ROS 2's distributed transform system that tracks the relationships between all coordinate frames over time, allowing you to:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Transform sensor data between different coordinate frames"}),"\n",(0,t.jsx)(n.li,{children:"Understand where robot parts are relative to each other"}),"\n",(0,t.jsx)(n.li,{children:'Convert goals from "10 meters forward of the robot" to absolute map coordinates'}),"\n",(0,t.jsx)(n.li,{children:"Synchronize data from multiple sensors with different positions and orientations"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Real-world scenario"}),": Your robot's camera detects an object at (0.5, 0.2) in camera coordinates. To command the robot to drive to that object, you need to:"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Transform from camera frame \u2192 robot base frame"}),"\n",(0,t.jsx)(n.li,{children:"Transform from robot base \u2192 map frame (global coordinates)"}),"\n",(0,t.jsx)(n.li,{children:"Send navigation goal in map coordinates"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:'Without TF2, you\'d need to manually compute and manage dozens of geometric transformations. With TF2, you simply ask: "Where is this point in the map frame?" and the system handles all intermediate transformations automatically.'}),"\n",(0,t.jsx)(n.p,{children:"This chapter teaches you how to use TF2 to build robots that understand their geometry."}),"\n",(0,t.jsx)(n.h2,{id:"1-tf2-library-fundamentals",children:"1. TF2 Library Fundamentals"}),"\n",(0,t.jsx)(n.h3,{id:"what-is-tf2",children:"What is TF2?"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"TF2"})," is a distributed system for tracking coordinate frame relationships that:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Maintains a ",(0,t.jsx)(n.strong,{children:"tree structure"})," of coordinate frames"]}),"\n",(0,t.jsxs)(n.li,{children:["Stores transforms with ",(0,t.jsx)(n.strong,{children:"timestamps"})," (transform history)"]}),"\n",(0,t.jsxs)(n.li,{children:["Provides ",(0,t.jsx)(n.strong,{children:"efficient lookups"})," between any two frames"]}),"\n",(0,t.jsxs)(n.li,{children:["Handles ",(0,t.jsx)(n.strong,{children:"time synchronization"})," for moving frames"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Coordinate Frame"}),": A 3D coordinate system (origin point + orientation)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Every robot component has at least one frame"}),"\n",(0,t.jsxs)(n.li,{children:["Frames are named (e.g., ",(0,t.jsx)(n.code,{children:"base_link"}),", ",(0,t.jsx)(n.code,{children:"camera_link"}),", ",(0,t.jsx)(n.code,{children:"odom"}),", ",(0,t.jsx)(n.code,{children:"map"}),")"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Transform"}),": Describes how to convert from one frame to another"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Translation"}),": (x, y, z) offset in meters"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Rotation"}),": Quaternion (x, y, z, w) or Euler angles (roll, pitch, yaw)"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Transform Tree"}),": Directed acyclic graph of frame relationships"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Each frame has exactly ",(0,t.jsx)(n.strong,{children:"one parent"})]}),"\n",(0,t.jsxs)(n.li,{children:["Frames can have ",(0,t.jsx)(n.strong,{children:"multiple children"})]}),"\n",(0,t.jsxs)(n.li,{children:["There is typically one root frame (e.g., ",(0,t.jsx)(n.code,{children:"map"})," or ",(0,t.jsx)(n.code,{children:"odom"}),")"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"tf2-vs-tf-original",children:"TF2 vs TF (Original)"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Feature"}),(0,t.jsx)(n.th,{children:"TF (old)"}),(0,t.jsx)(n.th,{children:"TF2 (current)"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Performance"}),(0,t.jsx)(n.td,{children:"Slower"}),(0,t.jsx)(n.td,{children:"10x faster"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Message types"}),(0,t.jsx)(n.td,{children:"Custom"}),(0,t.jsx)(n.td,{children:"Standard geometry_msgs"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Extensibility"}),(0,t.jsx)(n.td,{children:"Limited"}),(0,t.jsx)(n.td,{children:"Plugin-based"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Python API"}),(0,t.jsx)(n.td,{children:"tf"}),(0,t.jsx)(n.td,{children:"tf2_ros, tf2_geometry_msgs"})]})]})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Always use TF2 in ROS 2"})," - the original TF is deprecated."]}),"\n",(0,t.jsx)(n.h3,{id:"key-tf2-packages",children:"Key TF2 Packages"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\n\n# Core TF2 libraries\nimport tf2_ros\nfrom tf2_ros import TransformBroadcaster, StaticTransformBroadcaster\nfrom tf2_ros import TransformListener, Buffer\n\n# Message types\nfrom geometry_msgs.msg import TransformStamped, PointStamped\nfrom tf2_geometry_msgs import do_transform_point\n"})}),"\n",(0,t.jsx)(n.h2,{id:"2-coordinate-frames-in-robotics",children:"2. Coordinate Frames in Robotics"}),"\n",(0,t.jsx)(n.h3,{id:"standard-frame-naming-conventions",children:"Standard Frame Naming Conventions"}),"\n",(0,t.jsx)(n.p,{children:"ROS 2 uses standardized frame names for consistency:"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsxs)(n.strong,{children:["1. ",(0,t.jsx)(n.code,{children:"map"})]})," - Fixed global frame"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Origin: Arbitrary point in the world"}),"\n",(0,t.jsx)(n.li,{children:"Never moves"}),"\n",(0,t.jsx)(n.li,{children:"Used for global navigation and localization"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsxs)(n.strong,{children:["2. ",(0,t.jsx)(n.code,{children:"odom"})]})," - Odometry frame"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Origin: Where robot started (or last reset)"}),"\n",(0,t.jsx)(n.li,{children:"Continuous, but drifts over time"}),"\n",(0,t.jsx)(n.li,{children:"Updated by wheel encoders or visual odometry"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsxs)(n.strong,{children:["3. ",(0,t.jsx)(n.code,{children:"base_link"})]})," - Robot's center"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Origin: Typically at center of rotation"}),"\n",(0,t.jsx)(n.li,{children:"Moves with the robot"}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Most important frame"})," - all robot parts defined relative to this"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"4. Sensor frames"})," - One per sensor"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"camera_link"}),", ",(0,t.jsx)(n.code,{children:"lidar_link"}),", ",(0,t.jsx)(n.code,{children:"imu_link"})]}),"\n",(0,t.jsxs)(n.li,{children:["Fixed relative to ",(0,t.jsx)(n.code,{children:"base_link"})]}),"\n",(0,t.jsx)(n.li,{children:"Defined by physical mounting position"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"5. End-effector frames"})," (for manipulators)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"gripper_link"}),", ",(0,t.jsx)(n.code,{children:"tool_frame"})]}),"\n",(0,t.jsxs)(n.li,{children:["May move relative to ",(0,t.jsx)(n.code,{children:"base_link"})," (for robot arms)"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"transform-tree-example",children:"Transform Tree Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"map\n \u2514\u2500 odom\n     \u2514\u2500 base_link\n         \u251c\u2500 laser_link\n         \u251c\u2500 camera_link\n         \u2514\u2500 imu_link\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Reading this tree:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"map"})," \u2192 ",(0,t.jsx)(n.code,{children:"odom"}),": Localization (updated by SLAM/AMCL)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"odom"})," \u2192 ",(0,t.jsx)(n.code,{children:"base_link"}),": Odometry (updated by wheel encoders)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"base_link"})," \u2192 ",(0,t.jsx)(n.code,{children:"laser_link"}),": Static (fixed sensor mount)"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"right-handed-coordinate-systems",children:"Right-Handed Coordinate Systems"}),"\n",(0,t.jsxs)(n.p,{children:["ROS 2 uses ",(0,t.jsx)(n.strong,{children:"right-handed coordinates"})," with standard axes:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"z (up)\n\u2502   x (forward)\n\u2502  \u2571\n\u2502 \u2571\n\u2502\u2571_____ y (left)\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Convention for mobile robots:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"X-axis"}),": Forward"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Y-axis"}),": Left"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Z-axis"}),": Up"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Convention for cameras (different!):"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Z-axis"}),": Forward (depth)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"X-axis"}),": Right"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Y-axis"}),": Down"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"3-broadcasting-transforms",children:"3. Broadcasting Transforms"}),"\n",(0,t.jsx)(n.h3,{id:"static-transforms",children:"Static Transforms"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Static transforms"})," never change - they represent fixed relationships (e.g., camera mounted on robot chassis)."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom tf2_ros import StaticTransformBroadcaster\nfrom geometry_msgs.msg import TransformStamped\nimport math\n\nclass StaticFramePublisher(Node):\n    def __init__(self):\n        super().__init__(\'static_frame_publisher\')\n\n        # Create static broadcaster\n        self.tf_static_broadcaster = StaticTransformBroadcaster(self)\n\n        # Publish camera transform\n        self.publish_camera_transform()\n\n    def publish_camera_transform(self):\n        """Publish static transform from base_link to camera_link"""\n        static_transform = TransformStamped()\n\n        # Header\n        static_transform.header.stamp = self.get_clock().now().to_msg()\n        static_transform.header.frame_id = \'base_link\'\n        static_transform.child_frame_id = \'camera_link\'\n\n        # Translation: camera is 0.3m forward, 0.05m up from base\n        static_transform.transform.translation.x = 0.3\n        static_transform.transform.translation.y = 0.0\n        static_transform.transform.translation.z = 0.05\n\n        # Rotation: camera tilted down 15 degrees\n        # Convert Euler (roll, pitch, yaw) to quaternion\n        roll = 0.0\n        pitch = math.radians(-15)  # Tilt down\n        yaw = 0.0\n\n        quat = self.euler_to_quaternion(roll, pitch, yaw)\n        static_transform.transform.rotation.x = quat[0]\n        static_transform.transform.rotation.y = quat[1]\n        static_transform.transform.rotation.z = quat[2]\n        static_transform.transform.rotation.w = quat[3]\n\n        # Send transform\n        self.tf_static_broadcaster.sendTransform(static_transform)\n        self.get_logger().info(\'Published static transform: base_link \u2192 camera_link\')\n\n    def euler_to_quaternion(self, roll, pitch, yaw):\n        """Convert Euler angles to quaternion"""\n        cy = math.cos(yaw * 0.5)\n        sy = math.sin(yaw * 0.5)\n        cp = math.cos(pitch * 0.5)\n        sp = math.sin(pitch * 0.5)\n        cr = math.cos(roll * 0.5)\n        sr = math.sin(roll * 0.5)\n\n        qx = sr * cp * cy - cr * sp * sy\n        qy = cr * sp * cy + sr * cp * sy\n        qz = cr * cp * sy - sr * sp * cy\n        qw = cr * cp * cy + sr * sp * sy\n\n        return [qx, qy, qz, qw]\n\ndef main():\n    rclpy.init()\n    node = StaticFramePublisher()\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Key points:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Static transforms are published ",(0,t.jsx)(n.strong,{children:"once"})," on startup"]}),"\n",(0,t.jsxs)(n.li,{children:["Use ",(0,t.jsx)(n.code,{children:"StaticTransformBroadcaster"})," not ",(0,t.jsx)(n.code,{children:"TransformBroadcaster"})]}),"\n",(0,t.jsxs)(n.li,{children:["Always use current timestamp from ",(0,t.jsx)(n.code,{children:"self.get_clock().now()"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"dynamic-transforms",children:"Dynamic Transforms"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Dynamic transforms"})," change over time - they represent moving relationships (e.g., robot moving in the world)."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from tf2_ros import TransformBroadcaster\nfrom nav_msgs.msg import Odometry\n\nclass OdometryToTF(Node):\n    def __init__(self):\n        super().__init__('odom_to_tf')\n\n        # Create dynamic broadcaster\n        self.tf_broadcaster = TransformBroadcaster(self)\n\n        # Subscribe to odometry\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            'odom',\n            self.odom_callback,\n            10\n        )\n\n    def odom_callback(self, msg):\n        \"\"\"Convert odometry message to TF transform\"\"\"\n        t = TransformStamped()\n\n        # Header - use timestamp from odometry message\n        t.header.stamp = msg.header.stamp\n        t.header.frame_id = 'odom'\n        t.child_frame_id = 'base_link'\n\n        # Copy translation from odometry\n        t.transform.translation.x = msg.pose.pose.position.x\n        t.transform.translation.y = msg.pose.pose.position.y\n        t.transform.translation.z = msg.pose.pose.position.z\n\n        # Copy rotation from odometry\n        t.transform.rotation = msg.pose.pose.orientation\n\n        # Broadcast transform\n        self.tf_broadcaster.sendTransform(t)\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Key points:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Dynamic transforms are published ",(0,t.jsx)(n.strong,{children:"continuously"})," (every update)"]}),"\n",(0,t.jsxs)(n.li,{children:["Use ",(0,t.jsx)(n.code,{children:"TransformBroadcaster"})," not ",(0,t.jsx)(n.code,{children:"StaticTransformBroadcaster"})]}),"\n",(0,t.jsx)(n.li,{children:"Use timestamps from sensor messages for time synchronization"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"4-listening-to-transforms",children:"4. Listening to Transforms"}),"\n",(0,t.jsx)(n.h3,{id:"transform-lookup",children:"Transform Lookup"}),"\n",(0,t.jsxs)(n.p,{children:["To ",(0,t.jsx)(n.strong,{children:"use"})," transforms (convert points between frames), you need a listener:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom tf2_ros import TransformListener, Buffer, LookupException\nfrom geometry_msgs.msg import PointStamped\nimport tf2_geometry_msgs\n\nclass FrameListener(Node):\n    def __init__(self):\n        super().__init__('frame_listener')\n\n        # Create buffer and listener\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Create timer to periodically look up transforms\n        self.timer = self.create_timer(1.0, self.lookup_transform)\n\n    def lookup_transform(self):\n        \"\"\"Look up transform from camera to base\"\"\"\n        try:\n            # Get transform from camera_link to base_link\n            # at the current time\n            transform = self.tf_buffer.lookup_transform(\n                'base_link',      # Target frame\n                'camera_link',    # Source frame\n                rclpy.time.Time()  # Time (Time() = latest available)\n            )\n\n            # Extract translation\n            trans = transform.transform.translation\n            self.get_logger().info(\n                f'Camera is at ({trans.x:.2f}, {trans.y:.2f}, {trans.z:.2f}) '\n                f'relative to base_link'\n            )\n\n        except LookupException as e:\n            self.get_logger().error(f'Transform lookup failed: {e}')\n"})}),"\n",(0,t.jsx)(n.h3,{id:"transforming-points",children:"Transforming Points"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def transform_point_example(self):\n    \"\"\"Transform a point from camera frame to map frame\"\"\"\n    # Create point in camera frame\n    point_in_camera = PointStamped()\n    point_in_camera.header.frame_id = 'camera_link'\n    point_in_camera.header.stamp = self.get_clock().now().to_msg()\n    point_in_camera.point.x = 1.0  # 1 meter in front of camera\n    point_in_camera.point.y = 0.0\n    point_in_camera.point.z = 0.0\n\n    try:\n        # Transform to map frame\n        point_in_map = self.tf_buffer.transform(\n            point_in_camera,\n            'map',  # Target frame\n            timeout=rclpy.duration.Duration(seconds=1.0)\n        )\n\n        self.get_logger().info(\n            f'Point in map frame: '\n            f'({point_in_map.point.x:.2f}, {point_in_map.point.y:.2f})'\n        )\n\n        return point_in_map\n\n    except Exception as e:\n        self.get_logger().error(f'Transform failed: {e}')\n        return None\n"})}),"\n",(0,t.jsx)(n.h3,{id:"time-travel-looking-up-past-transforms",children:"Time Travel: Looking Up Past Transforms"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Get transform as it was 2 seconds ago\npast_time = self.get_clock().now() - rclpy.duration.Duration(seconds=2.0)\n\ntransform = self.tf_buffer.lookup_transform(\n    'map',\n    'base_link',\n    past_time.to_msg()\n)\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Use cases for historical transforms:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Synchronize sensor data with different timestamps"}),"\n",(0,t.jsx)(n.li,{children:"Compute velocities from position changes"}),"\n",(0,t.jsx)(n.li,{children:"Replay logged data"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"5-command-line-tools",children:"5. Command-Line Tools"}),"\n",(0,t.jsx)(n.h3,{id:"view-transform-tree",children:"View Transform Tree"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Install tools (if not already installed)\nsudo apt install ros-humble-tf2-tools\n\n# View the transform tree\nros2 run tf2_tools view_frames\n\n# This creates frames.pdf showing the tree structure\n"})}),"\n",(0,t.jsx)(n.h3,{id:"echo-transforms-in-real-time",children:"Echo Transforms in Real-Time"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Print transform from map to base_link\nros2 run tf2_ros tf2_echo map base_link\n\n# Output shows:\n# - Translation (x, y, z)\n# - Rotation (quaternion and Euler)\n# - Update rate\n"})}),"\n",(0,t.jsx)(n.h3,{id:"monitor-transform-issues",children:"Monitor Transform Issues"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Check for problems in the transform tree\nros2 run tf2_ros tf2_monitor\n\n# Shows:\n# - Frame rates\n# - Average delays\n# - Missing frames\n"})}),"\n",(0,t.jsx)(n.h2,{id:"6-debugging-tf2-issues",children:"6. Debugging TF2 Issues"}),"\n",(0,t.jsx)(n.h3,{id:"common-problems",children:"Common Problems"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:'Problem 1: "Frame does not exist"'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Lookup would require extrapolation into the future.\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Causes:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Frame not being published"}),"\n",(0,t.jsx)(n.li,{children:"Timestamp in the future"}),"\n",(0,t.jsx)(n.li,{children:"TF buffer not initialized"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Check if transform exists\nif self.tf_buffer.can_transform('map', 'base_link', rclpy.time.Time()):\n    transform = self.tf_buffer.lookup_transform(...)\nelse:\n    self.get_logger().warn('Transform not available yet')\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Problem 2: Multiple parents"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"TF_REPEATED_DATA: Frame [base_link] has multiple parents!\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Cause:"})," Two nodes are publishing the same transform"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Solution:"})," Ensure each transform has exactly one broadcaster"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Problem 3: Timestamp errors"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Lookup would require extrapolation into the past.\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Cause:"})," Requesting transform at time before it was published"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Solution:"})," Use latest available transform:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"transform = self.tf_buffer.lookup_transform(\n    'map', 'base_link',\n    rclpy.time.Time(),  # Latest available, not specific time\n    timeout=rclpy.duration.Duration(seconds=1.0)\n)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"7-practical-example-object-detection-in-map-frame",children:"7. Practical Example: Object Detection in Map Frame"}),"\n",(0,t.jsx)(n.p,{children:"Let's build a complete example: A robot detects an object with its camera and publishes its location in the map frame."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom tf2_ros import TransformListener, Buffer\nfrom geometry_msgs.msg import PointStamped\nfrom visualization_msgs.msg import Marker\n\nclass ObjectDetectorTF(Node):\n    def __init__(self):\n        super().__init__('object_detector_tf')\n\n        # TF listener\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Publisher for detected object in map frame\n        self.marker_pub = self.create_publisher(Marker, 'detected_object', 10)\n\n        # Timer to simulate object detection\n        self.timer = self.create_timer(2.0, self.detect_object)\n\n    def detect_object(self):\n        \"\"\"Simulate detecting an object 2m in front of camera\"\"\"\n        # Object detected at (2, 0, 0) in camera frame\n        object_camera = PointStamped()\n        object_camera.header.frame_id = 'camera_link'\n        object_camera.header.stamp = self.get_clock().now().to_msg()\n        object_camera.point.x = 2.0  # 2 meters forward\n        object_camera.point.y = 0.0\n        object_camera.point.z = 0.0\n\n        try:\n            # Transform to map frame\n            object_map = self.tf_buffer.transform(\n                object_camera,\n                'map',\n                timeout=rclpy.duration.Duration(seconds=1.0)\n            )\n\n            self.get_logger().info(\n                f'Object detected in map frame: '\n                f'({object_map.point.x:.2f}, {object_map.point.y:.2f})'\n            )\n\n            # Publish marker for visualization in RViz\n            self.publish_marker(object_map)\n\n        except Exception as e:\n            self.get_logger().error(f'Could not transform object: {e}')\n\n    def publish_marker(self, point):\n        \"\"\"Publish visualization marker at detected object location\"\"\"\n        marker = Marker()\n        marker.header = point.header\n        marker.type = Marker.SPHERE\n        marker.action = Marker.ADD\n\n        # Position\n        marker.pose.position = point.point\n        marker.pose.orientation.w = 1.0\n\n        # Size and color\n        marker.scale.x = 0.2\n        marker.scale.y = 0.2\n        marker.scale.z = 0.2\n        marker.color.r = 1.0\n        marker.color.g = 0.0\n        marker.color.b = 0.0\n        marker.color.a = 1.0\n\n        self.marker_pub.publish(marker)\n\ndef main():\n    rclpy.init()\n    node = ObjectDetectorTF()\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n"})}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(n.p,{children:"Key takeaways from this chapter:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TF2"})," manages coordinate frame relationships in a tree structure"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Static transforms"})," (fixed mounts) use ",(0,t.jsx)(n.code,{children:"StaticTransformBroadcaster"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Dynamic transforms"})," (moving parts) use ",(0,t.jsx)(n.code,{children:"TransformBroadcaster"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Transform lookup"})," converts data between frames using ",(0,t.jsx)(n.code,{children:"Buffer"})," and ",(0,t.jsx)(n.code,{children:"TransformListener"})]}),"\n",(0,t.jsxs)(n.li,{children:["Standard frames: ",(0,t.jsx)(n.code,{children:"map"})," (global), ",(0,t.jsx)(n.code,{children:"odom"})," (local), ",(0,t.jsx)(n.code,{children:"base_link"})," (robot center)"]}),"\n",(0,t.jsxs)(n.li,{children:["Each frame has ",(0,t.jsx)(n.strong,{children:"one parent"})," and can have ",(0,t.jsx)(n.strong,{children:"multiple children"})]}),"\n",(0,t.jsx)(n.li,{children:"Always use timestamps from sensor messages for proper synchronization"}),"\n",(0,t.jsxs)(n.li,{children:["Command-line tools (",(0,t.jsx)(n.code,{children:"view_frames"}),", ",(0,t.jsx)(n.code,{children:"tf2_echo"}),", ",(0,t.jsx)(n.code,{children:"tf2_monitor"}),") help debug"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Best practices:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Publish static transforms once on startup"}),"\n",(0,t.jsx)(n.li,{children:"Always timestamp dynamic transforms with sensor data time"}),"\n",(0,t.jsxs)(n.li,{children:["Use ",(0,t.jsx)(n.code,{children:"rclpy.time.Time()"})," for latest available transform"]}),"\n",(0,t.jsxs)(n.li,{children:["Check ",(0,t.jsx)(n.code,{children:"can_transform()"})," before ",(0,t.jsx)(n.code,{children:"lookup_transform()"})," to avoid errors"]}),"\n",(0,t.jsx)(n.li,{children:"Keep transform tree simple - avoid deeply nested frames"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["What is the difference between ",(0,t.jsx)(n.code,{children:"StaticTransformBroadcaster"})," and ",(0,t.jsx)(n.code,{children:"TransformBroadcaster"}),"?"]}),"\n",(0,t.jsx)(n.li,{children:"Why does each frame have exactly one parent in the transform tree?"}),"\n",(0,t.jsxs)(n.li,{children:["When would you use ",(0,t.jsx)(n.code,{children:"rclpy.time.Time()"})," vs a specific timestamp in transform lookup?"]}),"\n",(0,t.jsxs)(n.li,{children:["How do you transform a point from ",(0,t.jsx)(n.code,{children:"camera_link"})," to ",(0,t.jsx)(n.code,{children:"map"})," frame?"]}),"\n",(0,t.jsx)(n.li,{children:'What causes the "Frame has multiple parents" error?'}),"\n",(0,t.jsx)(n.li,{children:"Why are timestamps important in TF2?"}),"\n",(0,t.jsx)(n.li,{children:"What is the standard convention for mobile robot coordinate axes?"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"hands-on-exercises",children:"Hands-on Exercises"}),"\n",(0,t.jsx)(n.h3,{id:"exercise-1-static-transform-publisher",children:"Exercise 1: Static Transform Publisher"}),"\n",(0,t.jsxs)(n.p,{children:["Create a node that publishes a static transform from ",(0,t.jsx)(n.code,{children:"base_link"})," to ",(0,t.jsx)(n.code,{children:"lidar_link"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"LiDAR mounted 0.2m forward, 0.3m up"}),"\n",(0,t.jsx)(n.li,{children:"No rotation"}),"\n",(0,t.jsxs)(n.li,{children:["Verify with ",(0,t.jsx)(n.code,{children:"ros2 run tf2_ros tf2_echo base_link lidar_link"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"exercise-2-dynamic-broadcaster",children:"Exercise 2: Dynamic Broadcaster"}),"\n",(0,t.jsxs)(n.p,{children:["Create a node that broadcasts ",(0,t.jsx)(n.code,{children:"odom \u2192 base_link"})," transform:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Move robot in a circle (radius 1m)"}),"\n",(0,t.jsx)(n.li,{children:"Update position at 10 Hz"}),"\n",(0,t.jsx)(n.li,{children:"Visualize in RViz"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"exercise-3-point-transformer",children:"Exercise 3: Point Transformer"}),"\n",(0,t.jsx)(n.p,{children:"Create a node that:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Subscribes to ",(0,t.jsx)(n.code,{children:"/clicked_point"})," (from RViz)"]}),"\n",(0,t.jsxs)(n.li,{children:["Transforms point from ",(0,t.jsx)(n.code,{children:"map"})," frame to ",(0,t.jsx)(n.code,{children:"base_link"})," frame"]}),"\n",(0,t.jsx)(n.li,{children:"Publishes result as a marker"}),"\n",(0,t.jsx)(n.li,{children:"Test by clicking points in RViz"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Concepts/About-Tf2.html",children:"TF2 Official Documentation"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials/Intermediate/Tf2/Introduction-To-Tf2.html",children:"TF2 Python Tutorials"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.ros.org/reps/rep-0105.html",children:"REP 105: Coordinate Frames for Mobile Platforms"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://eater.net/quaternions",children:"Quaternion Math Explained"})}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Next Chapter"}),": ",(0,t.jsx)(n.a,{href:"ch05-urdf-models.md",children:"URDF Robot Modeling \u2192"})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Previous Chapter"}),": ",(0,t.jsx)(n.a,{href:"/AI_COURSE_book/docs/module-01-ros2/week-04/ch03-python-rclpy",children:"\u2190 Python Programming with rclpy"})]})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var s=r(6540);const t={},i=s.createContext(t);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);