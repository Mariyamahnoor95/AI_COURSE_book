"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[740],{5630:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module-03-isaac/week-08/ch11-isaac-sim","title":"NVIDIA Isaac Sim","description":"Learning Objectives","source":"@site/docs/module-03-isaac/week-08/ch11-isaac-sim.md","sourceDirName":"module-03-isaac/week-08","slug":"/module-03-isaac/week-08/ch11-isaac-sim","permalink":"/AI_COURSE_book/docs/module-03-isaac/week-08/ch11-isaac-sim","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-03-isaac/week-08/ch11-isaac-sim.md","tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"id":"ch11-isaac-sim","title":"NVIDIA Isaac Sim","sidebar_label":"NVIDIA Isaac Sim","sidebar_position":12},"sidebar":"textbookSidebar","previous":{"title":"Module 3: NVIDIA Isaac (Weeks 8-10)","permalink":"/AI_COURSE_book/docs/module-03-isaac"},"next":{"title":"Isaac ROS Perception","permalink":"/AI_COURSE_book/docs/module-03-isaac/week-08/ch12-isaac-ros"}}');var s=i(4848),a=i(8453);const t={id:"ch11-isaac-sim",title:"NVIDIA Isaac Sim",sidebar_label:"NVIDIA Isaac Sim",sidebar_position:12},o="NVIDIA Isaac Sim",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"1. Isaac Sim Installation",id:"1-isaac-sim-installation",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Installation Methods",id:"installation-methods",level:3},{value:"First Launch",id:"first-launch",level:3},{value:"Verifying Installation",id:"verifying-installation",level:3},{value:"2. RTX Rendering",id:"2-rtx-rendering",level:2},{value:"What is RTX Ray Tracing?",id:"what-is-rtx-ray-tracing",level:3},{value:"Enabling RTX in Isaac Sim",id:"enabling-rtx-in-isaac-sim",level:3},{value:"RTX Features for Robotics",id:"rtx-features-for-robotics",level:3},{value:"Performance Tuning",id:"performance-tuning",level:3},{value:"3. PhysX 5.0 Physics",id:"3-physx-50-physics",level:2},{value:"What is PhysX 5.0?",id:"what-is-physx-50",level:3},{value:"Configuring Physics",id:"configuring-physics",level:3},{value:"Advanced Physics Features",id:"advanced-physics-features",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"4. Synthetic Data Generation",id:"4-synthetic-data-generation",level:2},{value:"Why Synthetic Data?",id:"why-synthetic-data",level:3},{value:"Basic Synthetic Data Pipeline",id:"basic-synthetic-data-pipeline",level:3},{value:"Ground Truth Annotations",id:"ground-truth-annotations",level:3},{value:"Synthetic Data Example: Object Detection",id:"synthetic-data-example-object-detection",level:3},{value:"5. Replicator for Data",id:"5-replicator-for-data",level:2},{value:"What is Replicator?",id:"what-is-replicator",level:3},{value:"Core Replicator Concepts",id:"core-replicator-concepts",level:3},{value:"Domain Randomization Example",id:"domain-randomization-example",level:3},{value:"Procedural Scene Generation",id:"procedural-scene-generation",level:3},{value:"Multi-Modal Data Collection",id:"multi-modal-data-collection",level:3},{value:"Summary",id:"summary",level:2},{value:"Review Questions",id:"review-questions",level:2},{value:"Hands-on Exercises",id:"hands-on-exercises",level:2},{value:"Exercise 1: First Isaac Sim Scene",id:"exercise-1-first-isaac-sim-scene",level:3},{value:"Exercise 2: Synthetic Dataset Generation",id:"exercise-2-synthetic-dataset-generation",level:3},{value:"Exercise 3: Physics Validation",id:"exercise-3-physics-validation",level:3},{value:"Further Reading",id:"further-reading",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"nvidia-isaac-sim",children:"NVIDIA Isaac Sim"})}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Install and configure NVIDIA Isaac Sim on your system"}),"\n",(0,s.jsx)(n.li,{children:"Understand RTX ray tracing for photorealistic robot simulation"}),"\n",(0,s.jsx)(n.li,{children:"Leverage PhysX 5.0 for accurate physics simulation"}),"\n",(0,s.jsx)(n.li,{children:"Generate synthetic training data for computer vision models"}),"\n",(0,s.jsx)(n.li,{children:"Use Replicator for procedural domain randomization"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsxs)(n.p,{children:["Gazebo is great for basic robot simulation, but modern Physical AI demands more: photorealistic rendering for vision algorithms, GPU-accelerated physics for complex manipulation, and massive-scale synthetic data generation for training deep learning models. ",(0,s.jsx)(n.strong,{children:"How do we simulate robots with the fidelity needed for real-world AI deployment?"})]}),"\n",(0,s.jsxs)(n.p,{children:["This is where ",(0,s.jsx)(n.strong,{children:"NVIDIA Isaac Sim"})," excels. Built on NVIDIA Omniverse, Isaac Sim provides:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"RTX ray tracing"}),": Photorealistic rendering with accurate lighting, shadows, reflections"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"PhysX 5.0"}),": GPU-accelerated physics supporting thousands of objects simultaneously"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ROS 2 integration"}),": Native support for ROS 2 topics, services, actions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Synthetic data"}),": Auto-labeled datasets for training perception models"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Replicator"}),": Procedural generation of randomized scenes at scale"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Why Isaac Sim matters for Physical AI:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Photorealistic vision"}),": Train CNNs on realistic synthetic images"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Scalable physics"}),": Simulate warehouses with hundreds of robots"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"GPU acceleration"}),": 10-100x faster than CPU-based simulators"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Domain randomization"}),": Generate millions of varied training scenarios"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Digital twins"}),": Create high-fidelity replicas of real environments"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Real-world impact"}),": Companies like Amazon Robotics use Isaac Sim to:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Train pick-and-place vision systems on 1M+ synthetic images"}),"\n",(0,s.jsx)(n.li,{children:"Simulate entire warehouses before deploying physical robots"}),"\n",(0,s.jsx)(n.li,{children:"Test edge cases (lighting changes, object occlusion) impossible to capture in real data"}),"\n",(0,s.jsx)(n.li,{children:"Reduce time-to-deployment from months to weeks"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This chapter introduces Isaac Sim and shows you how to harness GPU-accelerated simulation for Physical AI development."}),"\n",(0,s.jsx)(n.h2,{id:"1-isaac-sim-installation",children:"1. Isaac Sim Installation"}),"\n",(0,s.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Minimum specifications:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"GPU"}),": NVIDIA RTX 2070 or higher (RTX 30/40 series recommended)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"VRAM"}),": 8 GB minimum, 16+ GB recommended"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"RAM"}),": 32 GB system RAM"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"OS"}),": Ubuntu 20.04/22.04 or Windows 10/11"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Driver"}),": NVIDIA driver 525+ for RTX features"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Why GPU matters:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"RTX ray tracing requires RT cores (RTX 20 series+)"}),"\n",(0,s.jsx)(n.li,{children:"PhysX GPU acceleration needs CUDA cores"}),"\n",(0,s.jsx)(n.li,{children:"Replicator benefits from Tensor cores for AI"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"installation-methods",children:"Installation Methods"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Method 1: Omniverse Launcher (Recommended)"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Download NVIDIA Omniverse Launcher:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Visit: https://www.nvidia.com/en-us/omniverse/download/\nwget https://install.launcher.omniverse.nvidia.com/installers/omniverse-launcher-linux.AppImage\n\nchmod +x omniverse-launcher-linux.AppImage\n./omniverse-launcher-linux.AppImage\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsxs)(n.li,{children:["Install Isaac Sim through Launcher:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Open Omniverse Launcher"}),"\n",(0,s.jsx)(n.li,{children:'Go to "Exchange" tab'}),"\n",(0,s.jsx)(n.li,{children:'Search for "Isaac Sim"'}),"\n",(0,s.jsx)(n.li,{children:'Click "Install" (downloads ~20 GB)'}),"\n",(0,s.jsx)(n.li,{children:"Launch after installation completes"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Method 2: Container (for Clusters/CI)"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Pull Isaac Sim container\ndocker pull nvcr.io/nvidia/isaac-sim:2023.1.1\n\n# Run with GPU support\ndocker run --gpus all -it \\\n  -v ~/workspaces:/workspaces \\\n  nvcr.io/nvidia/isaac-sim:2023.1.1\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Method 3: pip Install (Python-only, no GUI)"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# For headless server deployments\npip install isaacsim-python\n"})}),"\n",(0,s.jsx)(n.h3,{id:"first-launch",children:"First Launch"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Launch Isaac Sim GUI\n~/.local/share/ov/pkg/isaac_sim-2023.1.1/isaac-sim.sh\n\n# Or launch with Python script\n~/.local/share/ov/pkg/isaac_sim-2023.1.1/python.sh my_script.py\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"First-time setup:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Accept EULA"}),"\n",(0,s.jsx)(n.li,{children:"GPU driver check (should show RTX features enabled)"}),"\n",(0,s.jsx)(n.li,{children:"Sample scene loads (warehouse environment)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"verifying-installation",children:"Verifying Installation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# test_isaac.py\nfrom isaacsim import SimulationApp\n\n# Initialize Isaac Sim\nsimulation_app = SimulationApp({"headless": False})\n\nfrom omni.isaac.core import World\nfrom omni.isaac.core.objects import DynamicCuboid\n\n# Create world\nworld = World()\n\n# Add a cube\ncube = DynamicCuboid(\n    prim_path="/World/Cube",\n    position=[0, 0, 1.0],\n    size=0.5,\n    color=[1.0, 0.0, 0.0]\n)\n\n# Simulate\nworld.reset()\nfor i in range(100):\n    world.step(render=True)\n\nsimulation_app.close()\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Expected output:"})," Red cube falls and bounces on ground plane"]}),"\n",(0,s.jsx)(n.h2,{id:"2-rtx-rendering",children:"2. RTX Rendering"}),"\n",(0,s.jsx)(n.h3,{id:"what-is-rtx-ray-tracing",children:"What is RTX Ray Tracing?"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Traditional rendering (rasterization):"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Fast but approximate"}),"\n",(0,s.jsx)(n.li,{children:"Pre-baked lighting"}),"\n",(0,s.jsx)(n.li,{children:"Screen-space reflections (inaccurate)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"RTX ray tracing:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Physically accurate light transport"}),"\n",(0,s.jsx)(n.li,{children:"Real-time global illumination"}),"\n",(0,s.jsx)(n.li,{children:"True reflections, refractions, shadows"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"enabling-rtx-in-isaac-sim",children:"Enabling RTX in Isaac Sim"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from isaacsim import SimulationApp\n\n# Launch with RTX enabled\nsimulation_app = SimulationApp({\n    "renderer": "RayTracedLighting",  # Enable RTX\n    "anti_aliasing": 3,  # DLSS/TAA level\n    "samples_per_pixel": 64,  # Ray samples (higher = better quality)\n    "headless": False\n})\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Renderer options:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:'"RayTracedLighting"'})," - Full RTX path tracing (most realistic)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:'"PathTracing"'})," - Offline-quality rendering (slow)"]}),"\n",(0,s.jsx)(n.li,{children:'`"Ir'}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:'adicance"` - Fast approximate (for prototyping)'}),"\n",(0,s.jsx)(n.h3,{id:"rtx-features-for-robotics",children:"RTX Features for Robotics"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"1. Accurate Shadows"})}),"\n",(0,s.jsx)(n.p,{children:"Robots operating in warehouses need to handle cast shadows from:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Overhead lights"}),"\n",(0,s.jsx)(n.li,{children:"Other robots"}),"\n",(0,s.jsx)(n.li,{children:"Shelving and obstacles"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Configure light with realistic shadows\nfrom pxr import UsdLux\n\nlight = UsdLux.DistantLight.Define(stage, "/World/Sun")\nlight.CreateIntensityAttr(5000)\nlight.CreateAngleAttr(0.53)  # Sun angular diameter\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"2. Material Reflections"})}),"\n",(0,s.jsx)(n.p,{children:"Shiny metal surfaces, glass, water require accurate reflections:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Create reflective material\nfrom omni.isaac.core.materials import PreviewSurface\n\nmetal_material = PreviewSurface(\n    prim_path="/World/Materials/Steel",\n    color=[0.8, 0.8, 0.8],\n    metallic=0.9,  # High metallicness\n    roughness=0.2   # Slight roughness\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"3. Depth of Field"})}),"\n",(0,s.jsx)(n.p,{children:"Cameras have finite aperture, creating realistic bokeh:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Camera with depth of field\ncamera = Camera(\n    prim_path="/World/Camera",\n    resolution=(1920, 1080)\n)\n\n# Enable DoF\ncamera.set_focal_length(24)  # mm\ncamera.set_focus_distance(2.0)  # meters\ncamera.set_f_stop(2.8)  # Wide aperture\n'})}),"\n",(0,s.jsx)(n.h3,{id:"performance-tuning",children:"Performance Tuning"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Quality vs Speed trade-off:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# High quality (slow, for dataset generation)\nconfig_high = {\n    "renderer": "RayTracedLighting",\n    "samples_per_pixel": 256,\n    "max_bounces": 12,\n    "denoiser": True\n}\n\n# Balanced (real-time training)\nconfig_balanced = {\n    "renderer": "RayTracedLighting",\n    "samples_per_pixel": 16,\n    "max_bounces": 4,\n    "denoiser": True,\n    "dlss": True  # AI upscaling\n}\n\n# Fast (interactive development)\nconfig_fast = {\n    "renderer": "Rasterization",\n    "anti_aliasing": 1\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"3-physx-50-physics",children:"3. PhysX 5.0 Physics"}),"\n",(0,s.jsx)(n.h3,{id:"what-is-physx-50",children:"What is PhysX 5.0?"}),"\n",(0,s.jsx)(n.p,{children:"NVIDIA's GPU-accelerated physics engine supporting:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Rigid body dynamics"}),": Boxes, spheres, meshes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Soft body simulation"}),": Cloth, deformable objects"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Fluid simulation"}),": Liquids, particles"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Articulations"}),": Robot joints, kinematic chains"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"GPU acceleration benefits:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Simulate 1000+ objects at 60 FPS"}),"\n",(0,s.jsx)(n.li,{children:"Parallel collision detection"}),"\n",(0,s.jsx)(n.li,{children:"Real-time soft body deformation"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"configuring-physics",children:"Configuring Physics"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from omni.isaac.core import World\n\nworld = World(\n    physics_dt=1.0/60.0,  # 60 Hz physics\n    rendering_dt=1.0/60.0,  # 60 Hz rendering\n    stage_units_in_meters=1.0,\n    physics_prim_path="/physicsScene",\n    device="GPU"  # Enable GPU physics\n)\n\n# Get physics scene for advanced config\nphysics_scene = world.get_physics_context().get_physics_scene_prim()\n\n# Configure solver\nphysics_scene.GetGravityDirectionAttr().Set([0, 0, -1])\nphysics_scene.GetGravityMagnitudeAttr().Set(9.81)\n\n# GPU settings\nphysics_scene.GetSolverTypeAttr().Set("TGS")  # Temporal Gauss-Seidel (GPU)\nphysics_scene.GetBroadphaseTypeAttr().Set("GPU")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"advanced-physics-features",children:"Advanced Physics Features"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"1. Contact Filtering"})}),"\n",(0,s.jsx)(n.p,{children:"Control which objects collide:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from pxr import UsdPhysics, PhysxSchema\n\n# Create collision groups\ncollision_api = PhysxSchema.PhysxCollisionAPI.Apply(cube_prim)\ncollision_api.CreateCollisionGroupAttr("group1")\n\n# Filter: group1 doesn\'t collide with group2\nfilter_api = UsdPhysics.FilteredPairsAPI.Apply(collision_api.GetPrim())\nfilter_api.CreateFilteredGroupsRel().AddTarget("/World/group2")\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"2. Articulation (Robot Joints)"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from omni.isaac.core.articulations import Articulation\n\n# Load robot URDF/USD\nrobot = Articulation(\n    prim_path="/World/Franka",\n    name="franka_robot"\n)\n\n# Set joint positions\nrobot.set_joint_positions([0, -0.785, 0, -2.356, 0, 1.571, 0.785])\n\n# Apply torques\nrobot.set_joint_efforts([0, 0, 0, 5.0, 0, 0, 0])  # 5 Nm on joint 4\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"3. Contact Sensors"})}),"\n",(0,s.jsx)(n.p,{children:"Detect collisions and measure forces:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from omni.isaac.sensor import ContactSensor\n\n# Add contact sensor to gripper\ncontact_sensor = ContactSensor(\n    prim_path="/World/Robot/gripper/contact_sensor",\n    min_threshold=0.1,  # Minimum force (N)\n    max_threshold=100.0,\n    radius=0.05\n)\n\n# Read contact data\nworld.step()\nin_contact = contact_sensor.is_in_contact()\nforce = contact_sensor.get_contact_force_matrix()  # [N, 3]\n'})}),"\n",(0,s.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Enable GPU pipeline for maximum performance\nfrom omni.physx import acquire_physx_interface\n\nphysx = acquire_physx_interface()\nphysx.update_simulation_loop_parameters(\n    use_gpu=True,\n    use_gpu_articulations=True,\n    use_gpu_contacts=True,\n    gpu_max_rigid_patch_count=1024*10  # More objects\n)\n"})}),"\n",(0,s.jsx)(n.h2,{id:"4-synthetic-data-generation",children:"4. Synthetic Data Generation"}),"\n",(0,s.jsx)(n.h3,{id:"why-synthetic-data",children:"Why Synthetic Data?"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Problem:"})," Training vision models requires millions of labeled images.\n",(0,s.jsx)(n.strong,{children:"Solution:"})," Generate photorealistic synthetic data with automatic labels."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Advantages over real data:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"\u2705 Infinite scale (generate millions of images)"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Perfect labels (bounding boxes, segmentation, depth)"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Edge cases (rare scenarios, varied lighting)"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Cost-effective (no manual labeling)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"basic-synthetic-data-pipeline",children:"Basic Synthetic Data Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from isaacsim import SimulationApp\nsimulation_app = SimulationApp({"headless": False})\n\nfrom omni.isaac.core import World\nfrom omni.isaac.sensor import Camera\nimport omni.replicator.core as rep\n\n# Create world\nworld = World()\n\n# Add camera\ncamera = Camera(\n    prim_path="/World/Camera",\n    position=[2, 2, 1.5],\n    resolution=(1280, 720)\n)\n\n# Create objects to detect\nfrom omni.isaac.core.objects import DynamicCuboid\ncube = DynamicCuboid(\n    prim_path="/World/Cube",\n    position=[0, 0, 0.5],\n    size=0.3,\n    color=[1.0, 0, 0]\n)\n\n# Capture annotated data\nworld.reset()\nfor frame in range(100):\n    world.step(render=True)\n\n    # Get RGB image\n    rgb = camera.get_rgb()\n\n    # Get semantic segmentation\n    seg = camera.get_semantic_segmentation()\n\n    # Get depth\n    depth = camera.get_depth()\n\n    # Get bounding boxes (2D)\n    bbox_2d = camera.get_bounding_box_2d()\n\n    # Save to disk\n    save_image(f"rgb_{frame:04d}.png", rgb)\n    save_annotation(f"bbox_{frame:04d}.json", bbox_2d)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"ground-truth-annotations",children:"Ground Truth Annotations"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Available annotations:"})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Type"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Use Case"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"RGB"}),(0,s.jsx)(n.td,{children:"Standard color image"}),(0,s.jsx)(n.td,{children:"Object detection"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Depth"}),(0,s.jsx)(n.td,{children:"Distance per pixel"}),(0,s.jsx)(n.td,{children:"3D reconstruction"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Semantic Seg"}),(0,s.jsx)(n.td,{children:"Class ID per pixel"}),(0,s.jsx)(n.td,{children:"Segmentation models"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Instance Seg"}),(0,s.jsx)(n.td,{children:"Object ID per pixel"}),(0,s.jsx)(n.td,{children:"Instance detection"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Bounding Box 2D"}),(0,s.jsx)(n.td,{children:"[x, y, w, h] boxes"}),(0,s.jsx)(n.td,{children:"YOLO, R-CNN"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Bounding Box 3D"}),(0,s.jsx)(n.td,{children:"3D cuboids"}),(0,s.jsx)(n.td,{children:"3D detection"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Normals"}),(0,s.jsx)(n.td,{children:"Surface orientation"}),(0,s.jsx)(n.td,{children:"Depth estimation"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Optical Flow"}),(0,s.jsx)(n.td,{children:"Motion vectors"}),(0,s.jsx)(n.td,{children:"Tracking, SLAM"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"synthetic-data-example-object-detection",children:"Synthetic Data Example: Object Detection"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import omni.replicator.core as rep\n\n# Randomize camera position\nwith rep.new_layer():\n    # Camera randomization\n    camera = rep.create.camera(position=(2, 0, 1))\n\n    with camera:\n        rep.modify.pose(\n            position=rep.distribution.uniform((-3, -3, 1), (3, 3, 3)),\n            look_at="/World/Cube"\n        )\n\n    # Light randomization\n    light = rep.create.light(\n        light_type="Sphere",\n        intensity=rep.distribution.uniform(1000, 5000),\n        temperature=rep.distribution.uniform(4000, 7000)\n    )\n\n    # Object randomization\n    cube = rep.get.prims(path_pattern="/World/Cube")\n    with cube:\n        rep.modify.pose(\n            position=rep.distribution.uniform((-1, -1, 0.5), (1, 1, 1.5))\n        )\n        rep.randomizer.color(colors=rep.distribution.choice([\n            [1, 0, 0],  # Red\n            [0, 1, 0],  # Green\n            [0, 0, 1]   # Blue\n        ]))\n\n    # Attach annotators\n    rgb_annotator = rep.AnnotatorRegistry.get_annotator("rgb")\n    bbox_2d_annotator = rep.AnnotatorRegistry.get_annotator("bounding_box_2d_loose")\n\n    # Render and save\n    rep.orchestrator.run()\n\n    for i in range(1000):\n        rep.orchestrator.step()\n        rgb = rgb_annotator.get_data()\n        bboxes = bbox_2d_annotator.get_data()\n\n        # Save outputs\n        save_coco_format(f"train/image_{i:05d}.png", rgb, bboxes)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"5-replicator-for-data",children:"5. Replicator for Data"}),"\n",(0,s.jsx)(n.h3,{id:"what-is-replicator",children:"What is Replicator?"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Replicator"})," is Isaac Sim's procedural generation framework for:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Domain randomization"}),": Vary lighting, textures, poses"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scene composition"}),": Procedurally place objects"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Large-scale data"}),": Generate millions of diverse scenarios"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"core-replicator-concepts",children:"Core Replicator Concepts"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"1. Randomizers"}),": Functions that vary scene properties\n",(0,s.jsx)(n.strong,{children:"2. Distributions"}),": Statistical distributions for randomization\n",(0,s.jsx)(n.strong,{children:"3. Annotators"}),": Extract ground truth data\n",(0,s.jsx)(n.strong,{children:"4. Orchestrator"}),": Controls randomization loop"]}),"\n",(0,s.jsx)(n.h3,{id:"domain-randomization-example",children:"Domain Randomization Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import omni.replicator.core as rep\n\n# Define randomizers\ndef randomize_lighting():\n    lights = rep.get.prims(path_pattern="/World/Light*")\n    with lights:\n        rep.modify.attribute(\n            "intensity",\n            rep.distribution.uniform(500, 5000)\n        )\n\ndef randomize_textures():\n    objects = rep.get.prims(semantics=[("class", "object")])\n    with objects:\n        rep.randomizer.materials(\n            textures=rep.utils.get_textures("/TextureLibrary/*")\n        )\n\ndef randomize_camera():\n    camera = rep.get.prims(path_pattern="/World/Camera")\n    with camera:\n        rep.modify.pose(\n            position=rep.distribution.sphere_surface(\n                center=(0, 0, 1),\n                radius=rep.distribution.uniform(1.5, 3.0)\n            ),\n            look_at=(0, 0, 0.5)\n        )\n\n# Register randomizers\nrep.randomizer.register(randomize_lighting)\nrep.randomizer.register(randomize_textures)\nrep.randomizer.register(randomize_camera)\n\n# Run randomization\nwith rep.trigger.on_frame(num_frames=5000):\n    rep.randomizer.randomize_lighting()\n    rep.randomizer.randomize_textures()\n    rep.randomizer.randomize_camera()\n'})}),"\n",(0,s.jsx)(n.h3,{id:"procedural-scene-generation",children:"Procedural Scene Generation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Generate warehouse with random object placement\nimport numpy as np\n\ndef generate_warehouse_scene(num_shelves=10, num_objects=50):\n    # Create floor\n    floor = rep.create.plane(\n        semantics=[("class", "floor")],\n        scale=(20, 20, 1)\n    )\n\n    # Procedural shelf placement\n    for i in range(num_shelves):\n        x = np.random.uniform(-10, 10)\n        y = np.random.uniform(-10, 10)\n\n        shelf = rep.create.from_usd(\n            "/Library/Warehouse/Shelf.usd",\n            semantics=[("class", "shelf")],\n            count=1\n        )\n\n        with shelf:\n            rep.modify.pose(position=(x, y, 0))\n\n    # Procedural object placement\n    for i in range(num_objects):\n        obj_type = np.random.choice(["box", "cylinder", "sphere"])\n\n        if obj_type == "box":\n            obj = rep.create.cube(\n                semantics=[("class", "object")],\n                scale=rep.distribution.uniform(0.1, 0.5)\n            )\n        elif obj_type == "cylinder":\n            obj = rep.create.cylinder(\n                semantics=[("class", "object")],\n                scale=rep.distribution.uniform(0.1, 0.5)\n            )\n        else:\n            obj = rep.create.sphere(\n                semantics=[("class", "object")],\n                scale=rep.distribution.uniform(0.1, 0.5)\n            )\n\n        with obj:\n            rep.modify.pose(\n                position=rep.distribution.uniform((-10, -10, 1), (10, 10, 3))\n            )\n\n# Generate scene\ngenerate_warehouse_scene(num_shelves=20, num_objects=100)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"multi-modal-data-collection",children:"Multi-Modal Data Collection"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Collect RGB, Depth, Segmentation, Bounding Boxes simultaneously\nwriter = rep.WriterRegistry.get("BasicWriter")\n\nwriter.initialize(\n    output_dir="/data/warehouse_dataset",\n    rgb=True,\n    bounding_box_2d_tight=True,\n    bounding_box_2d_loose=True,\n    semantic_segmentation=True,\n    distance_to_camera=True,\n    instance_segmentation=True,\n    normals=True\n)\n\n# Attach writer\nwriter.attach([camera])\n\n# Run data generation\nrep.orchestrator.run()\nfor i in range(10000):\n    rep.orchestrator.step()\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Output structure:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"/data/warehouse_dataset/\n\u251c\u2500\u2500 rgb/\n\u2502   \u251c\u2500\u2500 0000.png\n\u2502   \u251c\u2500\u2500 0001.png\n\u251c\u2500\u2500 semantic_segmentation/\n\u2502   \u251c\u2500\u2500 0000.png\n\u2502   \u251c\u2500\u2500 0001.png\n\u251c\u2500\u2500 bounding_box_2d_tight/\n\u2502   \u251c\u2500\u2500 0000.json\n\u2502   \u251c\u2500\u2500 0001.json\n\u2514\u2500\u2500 metadata.json\n"})}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"Key takeaways from this chapter:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac Sim"})," provides GPU-accelerated, photorealistic robot simulation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"RTX rendering"})," enables accurate lighting, shadows, and reflections for vision AI"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"PhysX 5.0"})," delivers high-performance physics with GPU acceleration"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Synthetic data"})," generation provides infinite, perfectly-labeled training data"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Replicator"})," enables domain randomization at scale for robust AI models"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"When to use Isaac Sim:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Training computer vision models (need photorealistic data)"}),"\n",(0,s.jsx)(n.li,{children:"Simulating complex manipulation (grasping, assembly)"}),"\n",(0,s.jsx)(n.li,{children:"Large-scale multi-robot scenarios (warehouses, factories)"}),"\n",(0,s.jsx)(n.li,{children:"Sim-to-real transfer with domain randomization"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"When to use Gazebo instead:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Simple mobile robots (basic navigation)"}),"\n",(0,s.jsx)(n.li,{children:"Rapid prototyping (faster iteration)"}),"\n",(0,s.jsx)(n.li,{children:"Standard ROS 2 testing"}),"\n",(0,s.jsx)(n.li,{children:"Limited GPU resources"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"What are the three main advantages of Isaac Sim over Gazebo?"}),"\n",(0,s.jsx)(n.li,{children:"Why is RTX ray tracing important for training vision models?"}),"\n",(0,s.jsx)(n.li,{children:"How does PhysX 5.0 GPU acceleration improve simulation performance?"}),"\n",(0,s.jsx)(n.li,{children:"What is the difference between semantic and instance segmentation?"}),"\n",(0,s.jsx)(n.li,{children:"How does domain randomization improve sim-to-real transfer?"}),"\n",(0,s.jsx)(n.li,{children:"What ground truth annotations can you extract from Isaac Sim?"}),"\n",(0,s.jsx)(n.li,{children:"Why generate synthetic data instead of collecting real images?"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"hands-on-exercises",children:"Hands-on Exercises"}),"\n",(0,s.jsx)(n.h3,{id:"exercise-1-first-isaac-sim-scene",children:"Exercise 1: First Isaac Sim Scene"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Install Isaac Sim via Omniverse Launcher"}),"\n",(0,s.jsx)(n.li,{children:"Create a scene with a robot, objects, and camera"}),"\n",(0,s.jsx)(n.li,{children:"Enable RTX rendering"}),"\n",(0,s.jsx)(n.li,{children:"Capture RGB and depth images"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"exercise-2-synthetic-dataset-generation",children:"Exercise 2: Synthetic Dataset Generation"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Set up a camera and 10 objects"}),"\n",(0,s.jsx)(n.li,{children:"Implement domain randomization (lighting, pose, color)"}),"\n",(0,s.jsx)(n.li,{children:"Generate 1000 images with bounding box annotations"}),"\n",(0,s.jsx)(n.li,{children:"Export in COCO format"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"exercise-3-physics-validation",children:"Exercise 3: Physics Validation"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Create a robot arm with 6 joints"}),"\n",(0,s.jsx)(n.li,{children:"Apply PhysX articulation"}),"\n",(0,s.jsx)(n.li,{children:"Command joint positions"}),"\n",(0,s.jsx)(n.li,{children:"Measure contact forces during grasping"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/index.html",children:"Isaac Sim Documentation"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/extensions/latest/ext_replicator.html",children:"Replicator Tutorials"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://nvidia-omniverse.github.io/PhysX/physx/5.1.0/index.html",children:"PhysX 5.0 Guide"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/1909.09119",children:"Synthetic Data for Deep Learning"})}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Next Chapter"}),": ",(0,s.jsx)(n.a,{href:"/AI_COURSE_book/docs/module-03-isaac/week-08/ch12-isaac-ros",children:"ROS 2 + Isaac Sim Integration \u2192"})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Previous Chapter"}),": ",(0,s.jsx)(n.a,{href:"/AI_COURSE_book/docs/module-02-digital-twin/week-07/ch10-digital-twin",children:"\u2190 Digital Twin Concepts"})]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var r=i(6540);const s={},a=r.createContext(s);function t(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);